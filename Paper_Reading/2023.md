# 1: 20230103
### Title: MVTN: Learning Multi-View Transformations for 3D Understanding
### Venue: TPAMI 2023
本文是一会议论文（ICCV 2021）扩刊到TPAMI。作者提出了一个Transformation Network：Multi-View Transformation Network (MVTN)，致力于提高3D classification and shape retrieval的性能。作者发布了一个Pytorch库：MVTorch，用来训练、测试和可视化多视角深度学习的pipeline。
# 2: 20230111
### Title: Camera Intrinsic Blur Kernel Estimation: A Reliable Framework
### Venue: CVPR 2015
# 3: 20230203
### Title: Adaptive Siamese Tracking with a Compact Latent Network
### Venue: TPAMI 2023
本文是一会议论文（ECCV 2020）扩刊到TPAMI。
# 4: 20230310
### Title: Jointly Defending DeepFake Manipulation and Adversarial Attack using Decoy Mechanism
### Venue: TPAMI 2023

# 5: 20230310
### Title: APARATE: Adaptive Adversarial Patch for CNN-based Monocular Depth Estimation for Autonomous Navigation
### Venue: ArXiv 202303


# 6: 20230310
### Title: Visual Analytics of Neuron Vulnerability to Adversarial Attacks on Convolutional Neural Networks
### Venue: ArXiv 202303

# 7: 20230310
### Title: AdvART: Adversarial Art for Camouflaged Object Detection Attacks
### Venue: ArXiv 202303

# 8: 20230313
### Title: CAFE: Catastrophic Data Leakage in Vertical Federated Learning
### Venue: NIPS 2021
Federated learning是保护数据隐私一个重要的手段，具体做法是在server and workers之间只传递参数，不传递数据。但是现有方法显示federated learning并不安全，privacy会从gradients信息中被推测出来。作者提出现有的方法有两个缺点，一是当batch-size设置得大时，攻击方法效果就不太好了，二是现有方法缺少理论证明。因此作者提出了CAFE，来解决这些问题。文中对data leakage attack有较好的survey。
# 9: 20230316
### Title: DisCO: Portrait Distortion Correction with Perspective-Aware 3D GANs
### Venue: ArXiv 202303
本文采用GAN-based方法来进行人脸照片的纵向失真校正。作者探讨了几种设计选择，以避免优化陷入次优解。首先通过联合优化相机内部/外部参数和面部潜在代码，使用透视扭曲的输入面部图像执行 GAN 反演。为了解决联合优化的模糊性，开发了焦距重新参数化、优化调度和几何正则化。 以适当的焦距和相机距离重新渲染肖像可以有效地纠正这些失真并产生更自然的效果。并且建立了一个用于人像透视畸变校正的定量评估协议。该协议有利于未来的研究。论文的写作、画图和思路都值得学习。
# 10: 20230316
### Title: CoCa: Contrastive Captioners are Image-Text Foundation Models
### Venue: ArXiv 202205
这是一个非常经典的工作，文章的写作、画图和思路设计非常值得学习。本文提出了Contrastive Captioner（CoCa）这一极简设计，它将图像文本编码器-解码器基础模型与contrastive loss 和captioning loss结合起来进行预训练。与所有解码器层都参与编码器输出的标准编码器解码器transformers不同，CoCa省略了解码器层前半部分中的cross-attention，来编码单模态文本表示，并级联了图像编码器的其余解码层，用于多模态图像文本表示。作者在单模态的图像和文本之间应用了对比损失，此外，多模态解码器输出上的captioning loss可以自动回归预测文本token。通过共享相同的网络层，可以以最小的开销高效地计算两个训练目标。
# 11: 20230327
### Title: FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness
### Venue: ArXiv 202327


















