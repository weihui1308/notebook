# 1: 20240101
### Title: Privacy-Preserving Representations Are Not Enough: Recovering Scene Content From Camera Poses
### Venue: CVPR 2023
视觉定位是一项从给定拍摄图像估算相机姿态的任务，也是一些三维计算机视觉应用的核心。现有的隐私保护定位工作旨在抵御可访问云服务的攻击者。本文通过实验展示，仅仅通过querying a localization服务，攻击者可以获取到scene中的细节信息。这种攻击基于这样一种观点，即现代视觉定位算法对外观和几何形状的变化具有鲁棒性。虽然这在一般情况下是一个理想的特性，但它也会导致算法定位那些与场景中的物体足够相似的物体。因此，攻击者可以向服务器查询足够多的物体图像，例如从互联网上获取的图像，其中一些图像将被定位。这样，攻击者就可以从服务返回的摄像头姿势（这是此类服务返回的最小信息）中了解物体的位置。本文开发了这种攻击的概念验证版本，并演示了其实际可行性。这种攻击对所使用的定位算法没有任何要求，因此也适用于隐私保护表示法。本文证明目前仅在隐私保护表征方面开展的工作是不够的。
# 2: 20240112
### Title: Thinking Image Color Aesthetics Assessment: Models, Datasets and Benchmarks
### Venue: ICCV 2023
本文关注的task是Image Color Aesthetics Assessment（ICCA），想比于Image Aesthetics Assessment关注image整体的美感，包含color, brightness, sharpness等，ICCA只关注color的影响，包括色彩和谐度和色彩组合等。作者提出了一个方法叫Delegate Transformer，可以自适应地为主色分配兴趣点，并模拟人类的颜色空间分割行为。此外，本文提出了一个数据集，ICAA17K，是一个color-oriented dataset。文章的写作和数据集的提出等值得借鉴。
# 3: 20240112
### Title: Scalable 3D Reconstruction From Single Particle X-Ray Diffraction Images Based on Online Machine Learning
### Venue: arXiv 202312



# 4: 20240123
### Title: Toward Verifiable and Reproducible Human Evaluation for Text-to-Image Generation
### Venue: CVPR 2023
本文研究的内容是对当前流行的文生图模型进行评估。作者提出虽然有FID和CLIPScore这些自动评估的指标，但人工评估仍是不可或缺的。但是当前的人工评估有许多不完全之处，例如评估细节在论文中没有披露，评估方式不一样等等，这些因素导致在对文生图模型进行评估时，结果不可靠，不同方法无法对比，无法复现。因此作者提出了一套详细的评估方法，利用亚马逊众包平台，记录了每一个步骤和评估细节。作者希望这一工作能成为人工评估的模板，推动人工评估在科研中的发展。

# 5: 20240227
### Title: HumanNeRF-SE: A Simple yet Effective Approach to Animate HumanNeRF with Diverse Poses
### Venue: CVPR 2024

# 6: 20240305
### Title: Segment Anything
### Venue: arXiv 2023

# 7: 20240305
### Title: EfficientSAM: Leveraged Masked Image Pretraining for Efficient Segment Anything
### Venue: CVPR 2024

# 8: 20240305
### Title: Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model
### Venue: arXiv 202402
本文提出了一个新的backbone: Vim，是Vision Mamba的缩写。与Vision Transformers类似，Vision Mamba受到Mamba在NLP任务上取得成功的启发，将其迁移到视觉任务上。作者认为有两个挑战：单向建模和缺乏位置意识。Vim结合了双向 SSMs 用于数据相关的全局视觉上下文建模，以及用于位置感知视觉识别的位置嵌入。实验显示Vim在性能和效率方法均优于DeiT。
# 9: 20240312
### Title: People Taking Photos That Faces Never Share: Privacy Protection and Fairness Enhancement from Camera to User
### Venue: AAAI 2023

# 10: 20240430
### Title: ImageNet-D: Benchmarking Neural Network Robustness on Diffusion Synthetic Object
### Venue: CVPR 2024
ImageNet-D利用diffusion model生成高质量的图像作为数据来源，从中挖掘困难样本组成最终数据集。实验结果表明，ImageNet-D有效降低了大量模型的测试准确率，包括最新的大模型CLIP和LLaVa-NeXT等。ImageNet-D从一个新的角度揭露了当前大模型的错误，有利于启发模型的进一步迭代。同时，整体数据集构建流程高效而灵活，可快速扩展到新的测试任务，为未来不同任务和场景构建测试基准提供了参考。

# 11: 20240718
### Title: Implicit Style-Content Separation using B-LoRA
### Venue: arXiv 202403
AIGC领域中的一项重要子任务就是对图像进行风格化处理，一般涉及到对图像视觉外观和纹理进行编辑（被视为是风格信息），同时保留其底层对象、结构和概念不变（被视为是内容信息）。为了达到这种编辑效果，就需要实现对图像中风格和内容进行分离。现有的方法通常需要训练专门的分离模型或者需要进行大量的优化，使用成本较高。本文介绍一篇全新的图像风格化工作，本文作者巧妙的将LoRA（低秩适应）机制引入到图像编辑领域，提出了一种称为B-LoRA的框架，该框架可以隐式分离单个图像中的风格和内容组件，同时继承了LoRA的各种优势，包括轻量化训练和即插即用等功能。此外，作者通过深度分析现有流行扩散模型（Stable Diffusion XL，SDXL）的内部架构，发现仅需要联合设置两个B-LoRA块即可以实现图像内容和风格的分离，从而显著的提升各种下游图像风格化任务的性能和效果。
