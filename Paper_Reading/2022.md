# 1: 20220506
### Title: Convolutional Neural Networks Can Be Deceived by Visual Illusions
### Venue: CVPR 2019
这篇文章研究了视觉错觉（Visual Illusions）相关的内容，例如相同的颜色在不同的背景下，人类的视觉会错认为不同的颜色。实验发现CNN可以像人类视觉系统一样，也会有视觉错觉的现象。
# 2: 20220507
### Title: Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks
### Venue: ICCV 2017
作者提出cyclegan来解决Unpaired Image-to-Image Translation问题，在训练GAN时，加入了Cycle Consistency Loss，模型不仅需要有能力translate X to Y，还要有能力translate Y to X。cyclegan被应用在多种任务中，有Object transfiguration，Season transfer，Photo generation from paintings等。
# 3: 20220509
### Title: Learning to Structure an Image with Few Colors
### Venue: CVPR 2020
本文研究了在严格的color约束下，图片如何保留更多的structure。提出ColorCNN，基于autoencoder，目标是image在极其小的颜色空间，尽可能地被classifier正确识别。
# 4: 20220509
### Title: Diverse Image-to-Image Translation via Disentangled Representations
### Venue: ECCV 2018
作者将image的解耦表达应用在Image-to-Image Translation，使其不再需要paired data做训练，同时增加了模型生成样本的多样性。提出DRIT方法。DRIT采用的仍然是GAN的结构，在其中加入了两个encoder，分别编码image的domain-invariant and domain-specific特征。
# 5: 20220509
### Title: Multimodal Unsupervised Image-to-Image Translation
### Venue: ECCV 2018
本文提出 Multimodal Unsupervised Image-to-image Translation (MUNIT) 框架来解决image-to-image translation任务中，转换的结果缺少多样性的问题。MUNIT将一张image解耦为content feature和style feature，使得方法可以实现example-guided image translation。
# 6: 20220510
### Title: Swapping Autoencoder for Deep Image Manipulation
### Venue: NIPS 2020
作者将image解耦为texture和structure，针对的任务是image manipulation。个人感觉与4和5做的工作非常相似。
# 7: 20220513
### Title: 绘画艺术图像的计算美学: 研究前沿与展望
### Venue: 自动化学报 2020
曾任国际实验美学协会主席的 Leder 将人类的审美行为建模为多层次的信息处理模型, 包含潜意识和主观意识两方面过程。潜意识过程包含对颜色、对比度、复杂性等底层信息的感知, 以及对个人经历和记忆的整合, 缺乏显式的信息输出, 难以被量化建模. 而主观意识过程包含显示分类、认知和评价三部分, 具有可被量化的中间结果或审美输出, 可以作为绘画图像计算美学的梳理参考。

本文将主观意识过程（分类、认知和评价），对应属性识别、内容理解和美学评价的计算美学问题，以这个角度展开每一部分的介绍。
# 8: 20220517
### Title: Improved Denoising Diffusion Probabilistic Models
### Venue: PMLR 2021
作者对DDPM做了一些改进，提高了采样速度，得到更好的log-likelihoods。
# 9: 20220519
### Title: Masked Autoencoders Are Scalable Vision Learners
### Venue: CVPR 2022
这篇文章将NLP任务的BERT模型应用于CV任务。采用encoder-decoder的架构，encoder的输入是image上一些随机的patch（把原图一些部分盖住），decoder的输入是encoder的输出潜编码和原图中被遮住的patch。这篇文章提出的是一个backbone，可以将其应用到别的下流任务中，如目标检测。
# 10: 20220528
### Title: ImageNet Classification with Deep Convolutional Neural Networks
### Venue: NIPS 2012
这是卷积神经网络的奠基之作，但现在看文章的写作有一些不美的地方，论文中的结论也有一些是不重要的。这个工作是在imagenet上做classification，在当年取得了非常好的效果，超过其余方法。惊奇的是，文章读起来很多名词依然是我们现在经常使用的，和读现在的paper相比没有违和感。
# 11: 20220530
### Title: Cognitive Psychology for Deep Neural Networks: A Shape Bias Case Study
### Venue: PMLR 2017
作者尝试从认知心理学的角度去探究深度神经网络的bias。本文探测的是shape bias，文章通过实验观察到：相比于Color， one shot learning models更倾向于通过shape去判断object的类别。
# 12: 20220530
### Title: Deep Residual Learning for Image Recognition
### Venue: CVPR 2016
作者提出了一个非常简单的深度卷积神经网络结构（残差链接），带来了非常大的效果提升。一定程度上解决了模型的效果随着网络深度增加而降低的问题。并且使得训练变得容易。深层原因：1. 因为残差结构，梯度变得打了，使SGD下降得更快也更有目标。2. 这种结构使得网络可以实现层数增加，但增加的层如果必要，可以对输入不做改变，一定程度上缓解了过拟合。
# 13: 20220531
### Title: Attention Is All You Need
### Venue: NIPS 2017
本文提出了一个新的神经网络架构：transformer。它没有用到卷积神经网络和循环神经网络，只用到了注意力，在翻译任务上取得好的效果。transformer现在已经应用在多种任务上，包括自然语言处理和计算机视觉。
# 14: 20220531
### Title: ILVR: Conditioning Method for Denoising Diffusion Probabilistic Models
### Venue: ICCV 2021
作者使用训练好的diffusion model，在reverse过程加入了matching the latent variable of a given reference image，使得生成的结果与the given reference image有语义相似性，通过这种方式来控制diffusion model的生成结果。
# 15: 20220601
### Title: A Gentle Introduction to Graph Neural Networks
### Venue: Distill 2021
这篇文章发表在Distill上面，主要介绍了Graph Neural Networks，包括以下内容：什么是Graph，如何把data表示为Graph，GNN如何处理data等。GNN和CNN是有一些相似的地方，比如pooling操作。文章有许多生动形象、可交互的图片。
# 16: 20220602
### Title: Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization
### Venue: ICCV 2017
推荐代码仓库：https://github.com/jacobgil/pytorch-grad-cam. 本文的工作对于理解神经网络有很大的意义。本文工作在不需要改变神经网络结构也不需要重新训练的情况下，可视化出在某次任务中神经网络关注的区域在哪里，并且用热力图可视化出来。推荐代码仓库有许多类似方法在不同任务中的实现。
# 17: 20220603
### Title: Generative Adversarial Nets
### Venue: NIPS 2014
生成对抗网络（GAN）的开创者。生成器、鉴别器等这些耳熟能详的词，在2014年提出来。时至今日，GAN已经有了很多改进，也在实验性能上取得了非常惊人的效果。GAN在生成样本的diversity方面存在不足，在生成速度和生成质量方面有优势。
# 18: 20220604
### Title: BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
### Venue: NAACL 2019
BERT对NLP任务的影响是巨大的。本文提出在语言类学习任务中，双向信息的重要性。在BERT上做微调效果很好，为下流任务提供了很好的效果提升。在本篇论文的结论中最大贡献是双向性（在写一篇论文的时候，最好有一个卖点，而不是这里好那里也好）。缺点是：与GPT（Improving Language Understanding by Generative Pre-Training）比，BERT用的是编码器，GPT用的是解码器。BERT做机器翻译、文本的摘要（生成类的任务）不好做。完整解决问题的思路：在一个很大的数据集上训练好一个很宽很深的模型，可以用在很多小的问题上，通过微调来全面提升小数据的性能（在计算机视觉领域用了很多年），模型越大，效果越好（很简单很暴力）。
# 19: 20220604
### Title: Text2Human: Text-Driven Controllable Human Image Generation
### Venue: SIGGRAPH 2022
本文的任务是生成包含human的image。在生成human穿的衣服的shape diversity和structure diversity上提出改进。本文的工作可以根据text生成对应样式的human image。生成human的衣服纹理这一块可以关注一下。采用的网络框架是VAE，构建了一个Hierarchical VQVAE。
# 20: 20220606
### Title: An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale
### Venue: ICLR 2021 Oral
作者用NLP任务中的BERT模型，来解决视觉任务（分类），提出了ViT: Vision Transformer。ViT和BERT模型的思路、结构等都是几乎一样的，不同的是输入由word变为了image patch。作者通过实验得出结论：ViT需要在大规模的数据集上才能取得超越CNN的效果。这个工作打破了CV和NLP之间的鸿沟，使得用一个model同时处理word和image成为显示，也就是处理多模态数据的model。
# 21: 20220607
### Title: Momentum Contrast for Unsupervised Visual Representation Learning
### Venue: CVPR 2020
一作Kaiming He，作者提出MoCo模型来学习特征，这些特征是通过无监督的对比学习获得的，学习到的特征可以迁移到下游任务中，比如分类和检测，效果可以媲美有监督学习的结果。该工作的官方代码写得非常好。
# 22: 20220616
### Title: Competition-Level Code Generation with AlphaCode
### Venue: arxiv 202202
作者团队DeepMind，提出AlphaCode，可以自动写代码的模型。作者用该模型去做算法竞赛的题，实验表明可以打败一般的人类算法程序员。用的架构是encoder-decoder，用的模型是transfermer。
# 23: 20220622
### Title: Advancing mathematics by guiding human intuition with AI
### Venue: Nature 202112 （DeepMind）
本文提出用机器学习的方法帮助数学家发现新的数学公式。X和Y是任意的两个数学物体，它俩之间是否有关系，是否值得数学家去探索，可以通过机器学习来验证。首先从X和Y中采样，得到数据集，然后用机器学习模型学习能够从X映射到Y，如果可以，再分析X中哪些样本是重要的，如果存在top的样本，数学家可以开始研究从X到Y的数学公式，并且重点关注X的top样本的属性。
# 24: 2022023
### Title: Learning Invisible Markers for Hidden Codes in Offline-to-online Photography
### Venue: CVPR 2022
本文解决的是信息传递或者信息加密的任务。它将QR code嵌入到一张image中，人类视觉感受不到，但通过Localization network可以定位到该QR code的位置，然后decoder可以还原出QR code，获得信息。文章的pipeline包含encoder，distortion network, localization network, decoder。采用分阶段的训练策略。
# 25: 2022024
### Title: End-to-end object detection with transformers
### Venue: ECCV 2020 （Facebook）
本文提出DETR，一个End-to-end的目标检测框架（之前的目标检测框架都很难做到End-to-end，需要NMS等）。DETR思想简单、实现简单、开源代码简洁优雅，检测效果达到了Faster RCNN的水平。它采用transformer的架构，引入object queries，相当于之前检测器种的anchor。在bounding box的匹配方面，用bipartite matching的思想来解决。（这篇文章中提到之前检测器的检测效果严重依赖一些初始猜想，具体见文章2.3部分）
# 26: 2022025
### Title: Swin Transformer: Hierarchical Vision Transformer using Shifted Windows
### Venue: ICCV 2021 best paper （MSRA）
作者将transformer作为一个骨干网络，用到了各类视觉任务中，取得了SOTA。本文继ViT之后，验证了transformer可以在视觉任务中取得好的效果。同类工作比较有名的有VGG，ResNet等。Swin是Shifted Windows的简称，本文提出Swin来解决patch块之间通信的问题，使得transformer可以提取到全局特征，并且降低了计算复杂度。
# 27: 2022027
### Title: Highly accurate protein structure prediction with AlphaFold
### Venue: Nature 202107
作者用transformer来预测人类蛋白质结构，达到了原子级别的误差。文章号称解决了50年来的一个难题。方法用了一个很复杂的网络结构。从本文工作可以看出transformer的流行度以及强大能力。
# 28: 2022028
### Title: Learning Transferable Visual Models From Natural Language Supervision
### Venue: ICML 2021
这是一个开创性的工作，它用language特征去监督视觉任务，从而获得好的特征表示。文章显示在不适用imagenet数据集的情况下（zero-shot），在imagenet上做测试，效果和resnet50差不多。作者做了很多的实验。这个工作显示了多模态特征的潜力。网络用的是transformer。
# 29: 2022028
### Title: Two-stream convolutional networks for action recognition in videos
### Venue: NIPS 2014
作者将卷积神经网络应用到处理视频数据的任务中（动作识别），之前有人尝试这么做，但并不work，作者提出了Two-stream网络，一个学习RGB图像的特征，一个学习光流的特征。（ps.光流指图像在时序维度上的变化情况）。通过这样的架构，作者成功达到了手工特征的精度，显示了深度学习在处理视频数据方面的潜力。Two-stream网络带来的启发：当model不work的时候，可以从数据端去考虑，例如本文的做法是直接给model提供抽出来的光流信息，以此让model学习时序维度的特征。
# 30: 2022029
### Title: Scaling Distributed Machine Learning with the Parameter Server
### Venue: OSDI 2014 (李沐)
作者为大规模的分布式机器学习设计了一个通用的系统，使得机器学习算法在面对这种大的数据量的任务时，可以更好地运行。由于文章属于系统方向和机器学习方向的交叉，在写作上值得借鉴。（ps.在paper中，如何向读者介绍一个技术：假设你的对面坐着一个非计算机专业人员，你要向他介绍，代入这样的角色进行写作）
# 31: 2022030
### Title: Language Models are Few-Shot Learners
### Venue: Arxiv 202006 (OpenAI)
本文提出一个语言模型GPT-3，它的学习参数有1700亿，同时训练的数据集也非常大。本文工作是延续GPT和GPT-2，也就是只用transformer网络的解码器，而BETR（Bidirectional Encoder Representations from Transformers）用的是编码器（两种不同的解决方案）。